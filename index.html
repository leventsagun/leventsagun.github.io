<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Levent Sagun</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <div class="page">
    <header>
      <h1>Levent Sagun</h1>
      <nav>
        <a href="#about">About</a>
        <a href="#research">Research</a>
        <a href="#publications">Selected work</a>
        <a href="#teaching">Teaching</a>
        <a href="#contact">Contact</a>
        <a href="things/CV-LeventSagun.pdf">CV (PDF)</a>
      </nav>
    </header>

    <section id="about">
      <h2>About</h2>
      <p>
        I am a Research Scientist at FAIR in Paris. I study
        failure modes in large models, with a focus on contextualized
        measurement for AI governance: construct validity, brittleness,
        spurious correlations, and fairness under distribution shift.
      </p>
      <p>
        Previously, I was a postdoctoral fellow at EPFL and ENS Paris
        as part of the Simons Collaboration on Cracking the Glass Problem.
        I received my Ph.D. in Mathematics from the Courant Institute of
        Mathematical Sciences at NYU.
      </p>
    </section>

    <section id="research">
      <h2>Research interests</h2>
      <ul>
        <li>Contextualized measurement for AI governance: construct validity and value-dependence</li>
        <li>Failure modes in large models: brittleness, spurious correlations, and bias amplification</li>
        <li>Robustness and reliability of large models and distribution shift</li>
        <li>Optimization, over-parameterization, and inductive biases in deep learning</li>
      </ul>
    </section>

    <section id="publications">
      <h2>Selected recent work</h2>
        <p class="selected-work-summary">
          Recent publications spanning contextualized evaluation, representational harms, and model brittleness:
        </p>
      <ul>
        <li>
          <strong>LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance.</strong><br />
          P. Haller, M. Ibrahim, P. Kirichenko, L. Sagun, S. Bell.
          <em>arXiv 2025.</em>
        </li>
        <li>
          <strong>Issues in Measuring the Fairness of Social Representation in Synthetic (Speech) Data.</strong><br />
          A. Subramonian, B. Sheppard, L. Sagun.
          <em>Synthetic Data Workshop at Aarhus Decennial Conference 2025.</em>
        </li>
        <li>
            <strong>Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models.</strong><br />
            C. Shaib, V. Suriyakumar, L. Sagun, B. Wallace, M. Ghassemi.
            <em>Spotlight at NeurIPS 2025.</em>
        </li>
        <li>
          <strong>On the lack of queer voices in diverse speech datasets.</strong><br />
          B. Sheppard, E. Ovalle, A. Williams, L. Sagun.
          <em>Social Science and Language Models workshop at Weizenbaum Institute 2025 &amp; Speech AI for All Workshop at CHI 2025.</em>
        </li>
        <li>
          <strong>The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models.</strong><br />
          A. Ovalle, K. L. Pavasovic, L. Martin, L. Zettlemoyer, E. M. Smith, K.-W. Chang, A. Williams, L. Sagun.
          <em>Queer in AI at NeurIPS 2024 &amp; FAccT 2025.</em>
        </li>
        <li>
          <strong>An Effective Theory of Bias Amplification.</strong><br />
          A. Subramonian, S. J. Bell, L. Sagun, E. Dohmatob.
          <em>ICLR 2025.</em>
        </li>
        <li>
          <strong>A Differentiable Rank-Based Objective For Better Feature Learning.</strong><br />
          K. Lehman Pavasovic, D. Lopez-Paz, G. Biroli, L. Sagun.
          <em>ICLR 2025.</em>
        </li>
        <li>
          <strong>On generated vs collected data.</strong><br />
          L. Sagun, K. Ahuja, E. Dohmatob, J. Kempe.
          <em>The Workshop on Global AI Cultures at ICLR, 2024.</em>
        </li>
        <li>
          <strong>Simplicity bias leads to amplified performance disparities.</strong><br />
          S. Bell, L. Sagun.
          <em>FAccT 2023.</em>
        </li>
        <li>
          <strong>Fairness Indicators for Systematic Assessments of Visual Feature Extractors.</strong><br />
          P. Goyal, A. R. Soriano, C. Hazirbas, L. Sagun, N. Usunier.
          <em>FAccT 2022.</em>
        </li>
      </ul>
      <p>
        For a full and up-to-date list of publications, see
        <a href="https://scholar.google.com/citations?user=-iPZaBcAAAAJ&hl=en">Google Scholar</a>.
      </p>
    </section>

    <section id="mentoring">
      <h2>Mentoring</h2>
      <p>
        I've been fortunate to be able to support brilliant PhD students, postdocs, and interns working on robustness, evaluation, and the social impact of large models.
      </p>
      <ul>          
        <strong>PhD Interns</strong>
        <li>Chantal Shaib (2025)</li>
        <li>Brooklyn Sheppard (2024)</li>
        <li>Arjun Subramonian (2024)</li>
        <li>Elia Ovalle (2023)</li>
        <li>Arjun Subramonian (2022)</li>
        <li>Sam Bell (2021)</li>
        <li>Berfin Simsek (2020)</li>
      </ul>
      <ul>
        <strong>PhD students</strong>
        <li>Nicole Osayande (starting 2026)</li>
        <li>Krunoslav Lehman Pavasovic (2024–2025)</li>
        <li>Stéphane d’Ascoli (2019-2022)</li>
      </ul>
      <ul>
        <strong>Postdocs</strong>
        <li>Sam Bell (2022–2023)</li>
      </ul>
    </section>
    
    <section id="teaching">
      <h2>Teaching</h2>
      <p>
        I have taught and assisted courses in probability, statistics, machine
        learning, and data science at NYU’s Courant Institute and Center for
        Data Science, and have given invited lectures and short courses on deep
        learning and values in AI.
      </p>
    </section>

    <section id="contact" class="contact">
      <h2>Contact</h2>
      <p>Email: leventsagun@{gmail or meta}.com </p>
      <p>Google Scholar:
        <a href="https://scholar.google.com/citations?user=-iPZaBcAAAAJ&hl=en">
          Profile
        </a>
      </p>
      <p>GitHub:
        <a href="https://github.com/leventsagun">github.com/leventsagun</a>
      </p>
    </section>

    <footer>
      <p>Last updated: November 2025.</p>
    </footer>
  </div>
</body>
</html>
